{
 "cells": [
  {
   "cell_type": "code",
"execution_count": 1,
   "id": "480547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bf4c0",
   "metadata": {},
   "source": [
    "## General rules\n",
    "1. update group when working and what sections\n",
    "2. Try to be comprehensive as you write! Leave short markdown descriptions for the average reader to understand what you're doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e22eb",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### [FILL IN WITH PROJECT DESCRIPTION]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63184edd",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 2,
   "id": "732e6a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/bassamhajjawi/.cache/kagglehub/datasets/eduardo4jesus/stanford-cars-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"eduardo4jesus/stanford-cars-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 3,
   "id": "bdd1b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Users/bassamhajjawi/.cache/kagglehub/datasets/eduardo4jesus/stanford-cars-dataset/versions/1\n",
      "Folders/files inside the dataset:\n",
      "['cars_train', 'cars_test', 'car_devkit']\n",
      "Files inside devkit\n",
      "['cars_test_annos.mat', 'eval_train.m', 'cars_meta.mat', 'README.txt', 'cars_train_annos.mat', 'train_perfect_preds.txt']\n"
     ]
    }
   ],
   "source": [
    "# Explore directories/files\n",
    "print(\"Path:\", path)\n",
    "print(\"Folders/files inside the dataset:\")\n",
    "dir = os.listdir(path)\n",
    "print(dir)\n",
    "devpath = path + '/car_devkit/devkit'\n",
    "print('Files inside devkit')\n",
    "print(os.listdir(devpath))\n",
    "metapath = devpath + \"/cars_meta.mat\""
   ]
  },
  {
   "cell_type": "code",
"execution_count": 4,
   "id": "604f0f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>class_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Acura RL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Acura TL Type-S 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Acura TSX Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>Volkswagen Beetle Hatchback 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>193</td>\n",
       "      <td>Volvo C30 Hatchback 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>194</td>\n",
       "      <td>Volvo 240 Sedan 1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>195</td>\n",
       "      <td>Volvo XC90 SUV 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                       class_names\n",
       "0        1        AM General Hummer SUV 2000\n",
       "1        2               Acura RL Sedan 2012\n",
       "2        3               Acura TL Sedan 2012\n",
       "3        4              Acura TL Type-S 2008\n",
       "4        5              Acura TSX Sedan 2012\n",
       "..     ...                               ...\n",
       "191    192  Volkswagen Beetle Hatchback 2012\n",
       "192    193          Volvo C30 Hatchback 2012\n",
       "193    194              Volvo 240 Sedan 1993\n",
       "194    195               Volvo XC90 SUV 2007\n",
       "195    196     smart fortwo Convertible 2012\n",
       "\n",
       "[196 rows x 2 columns]"
      ]
     },
"execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta = loadmat(metapath)\n",
    "\n",
    "train_dir = os.path.join(path, 'cars_train' )\n",
    "test_dir = os.path.join(path, 'cars_test')\n",
    "class_names = [c[0] for c in meta[\"class_names\"][0]]\n",
    "class_index = range(1, len(class_names) + 1) # classes are labeled w/ 1 based labeling\n",
    "\n",
    "classes = pd.DataFrame( {\n",
    "    \"label\": class_index,\n",
    "    \"class_names\" : class_names\n",
    "})\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 5,
   "id": "db3cb428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filen</th>\n",
       "      <th>train_labels</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>Audi TTS Coupe 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>91</td>\n",
       "      <td>Dodge Dakota Club Cab 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>134</td>\n",
       "      <td>Hyundai Sonata Hybrid Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>106</td>\n",
       "      <td>Ford F-450 Super Duty Crew Cab 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>08140.jpg</td>\n",
       "      <td>78</td>\n",
       "      <td>Chrysler Town and Country Minivan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>08141.jpg</td>\n",
       "      <td>196</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>08142.jpg</td>\n",
       "      <td>163</td>\n",
       "      <td>Mercedes-Benz SL-Class Coupe 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>08143.jpg</td>\n",
       "      <td>112</td>\n",
       "      <td>Ford GT Coupe 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>08144.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>Audi 100 Sedan 1994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filen  train_labels                              class_name\n",
       "0     00001.jpg            14                     Audi TTS Coupe 2012\n",
       "1     00002.jpg             3                     Acura TL Sedan 2012\n",
       "2     00003.jpg            91              Dodge Dakota Club Cab 2007\n",
       "3     00004.jpg           134        Hyundai Sonata Hybrid Sedan 2012\n",
       "4     00005.jpg           106     Ford F-450 Super Duty Crew Cab 2012\n",
       "...         ...           ...                                     ...\n",
       "8139  08140.jpg            78  Chrysler Town and Country Minivan 2012\n",
       "8140  08141.jpg           196           smart fortwo Convertible 2012\n",
       "8141  08142.jpg           163       Mercedes-Benz SL-Class Coupe 2009\n",
       "8142  08143.jpg           112                      Ford GT Coupe 2006\n",
       "8143  08144.jpg            17                     Audi 100 Sedan 1994\n",
       "\n",
       "[8144 rows x 3 columns]"
      ]
     },
"execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ann = loadmat(os.path.join(devpath, 'cars_train_annos.mat'))\n",
    "train_ann = train_ann[\"annotations\"][0] # index 4 is label for each train image\n",
    "test_ann = loadmat(os.path.join(devpath, 'cars_test_annos.mat'))\n",
    "test_ann = test_ann[\"annotations\"][0] # no test labels, will split up train_ann to train/test\n",
    "train_labels = [i[4][0][0] for i in train_ann]\n",
    "file_names = [i[5][0] for i in train_ann]\n",
    "\n",
    "\n",
    "data_dict = {\n",
    "    \"filen\" : file_names,\n",
    "    \"train_labels\" : train_labels\n",
    "}\n",
    "\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "data[\"class_name\"] = data[\"train_labels\"].map(\n",
    "    dict(zip(classes[\"label\"], classes[\"class_names\"]))\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f97d3-e2f2-4af0-a55d-e5a06b044314",
   "metadata": {},
   "source": [
    "## Body types work:"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 6,
   "id": "3cb07708-d08b-4c2b-ba76-484ca922c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_types = [\n",
    "    \"Coupe\", \"Sedan\", \"SUV\", \"Hatchback\",\n",
    "    \"Convertible\", \"Minivan\", \"Wagon\", \"Crossover\", \"Van\", \"Cab\"\n",
    "]\n",
    "\n",
    "def find_body_type(name):\n",
    "    name_lower = name.lower()\n",
    "    \n",
    "    for body in body_types:\n",
    "        if body.lower() in name_lower:\n",
    "            return body\n",
    "    #coupes\n",
    "    if any(x in name_lower for x in [\"corvette\", \"camaro\", \"mustang\", \"challenger\", \"370z\", \"350z\", \"supra\", \"xk\", \"xkr\", \"integra\", \"gallardo\"]):\n",
    "        return \"Coupe\"\n",
    "\n",
    "    # Sedans\n",
    "    if any(x in name_lower for x in [\"charger\", \"chrysler 300\", \"cobalt\", \"impala\", \"malibu\", \"accord\", \"civic\", \"corolla\", \n",
    "                                     \"jetta\", \"regal\", \"tl type-s\"]):\n",
    "        return \"Sedan\"\n",
    "\n",
    "    # SUVs \n",
    "    if any(x in name_lower for x in [\"grand cherokee\", \"cherokee\", \"durango\", \"rav4\", \"cr-v\", \"crv\", \"rogue\", \"highlander\", \"pilot\", \"tahoe\", \n",
    "                                     \"explorer\", \"escape\", \"equinox\",\"trailblazer\"]):\n",
    "        return \"SUV\"\n",
    "\n",
    "    #hatchbacks\n",
    "    if any(x in name_lower for x in [\"golf\", \"fit\", \"hhr\", \"impreza hatch\", \"mazda3 hatch\", \"sportwagen\",\"fiat 500\"]):\n",
    "        return \"Hatchback\"\n",
    "\n",
    "    # Trucks\n",
    "    if any(x in name_lower for x in [\"f-150\", \"f150\", \"f-250\", \"ram\", \"silverado\", \"sierra\", \"tacoma\", \"tundra\", \"ranger\", \"colorado\"]):\n",
    "        return \"Truck\"\n",
    "\n",
    "    # Vans / Minivans\n",
    "    if any(x in name_lower for x in [\"caravan\", \"odyssey\", \"sienna\", \"transit\", \"express van\", \"sprinter\"]):\n",
    "        return \"Van\"\n",
    "\n",
    "    # other\n",
    "    if \"srt\" in name_lower or \"ss\" in name_lower or \"hellcat\" in name_lower or \"z06\" in name_lower or \"zl1\" in name_lower:\n",
    "        if any(x in name_lower for x in [\"charger\", \"chrysler 300\", \"cts\"]):\n",
    "            return \"Sedan\"\n",
    "        if any(x in name_lower for x in [\"corvette\", \"camaro\", \"challenger\", \"mustang\"]):\n",
    "            return \"Coupe\"\n",
    "\n",
    "    if \"cab\" in name_lower:\n",
    "        return \"Cab\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "data[\"body type\"] = data[\"class_name\"].apply(find_body_type)\n",
    "data.loc[data[\"body type\"] == \"Cab\", \"body type\"] = \"Truck\"\n",
    "data.loc[data[\"body type\"] == \"Minivan\", \"body type\"] = \"Van\""
   ]
  },
  {
   "cell_type": "code",
"execution_count": 7,
   "id": "5e0f9b8d-c9e5-4bf0-9534-050cab09541a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filen</th>\n",
       "      <th>train_labels</th>\n",
       "      <th>class_name</th>\n",
       "      <th>body type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>Audi TTS Coupe 2012</td>\n",
       "      <td>Coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "      <td>Sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>91</td>\n",
       "      <td>Dodge Dakota Club Cab 2007</td>\n",
       "      <td>Truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>134</td>\n",
       "      <td>Hyundai Sonata Hybrid Sedan 2012</td>\n",
       "      <td>Sedan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005.jpg</td>\n",
       "      <td>106</td>\n",
       "      <td>Ford F-450 Super Duty Crew Cab 2012</td>\n",
       "      <td>Truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>08140.jpg</td>\n",
       "      <td>78</td>\n",
       "      <td>Chrysler Town and Country Minivan 2012</td>\n",
       "      <td>Van</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>08141.jpg</td>\n",
       "      <td>196</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>Convertible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>08142.jpg</td>\n",
       "      <td>163</td>\n",
       "      <td>Mercedes-Benz SL-Class Coupe 2009</td>\n",
       "      <td>Coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>08143.jpg</td>\n",
       "      <td>112</td>\n",
       "      <td>Ford GT Coupe 2006</td>\n",
       "      <td>Coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>08144.jpg</td>\n",
       "      <td>17</td>\n",
       "      <td>Audi 100 Sedan 1994</td>\n",
       "      <td>Sedan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8144 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filen  train_labels                              class_name  \\\n",
       "0     00001.jpg            14                     Audi TTS Coupe 2012   \n",
       "1     00002.jpg             3                     Acura TL Sedan 2012   \n",
       "2     00003.jpg            91              Dodge Dakota Club Cab 2007   \n",
       "3     00004.jpg           134        Hyundai Sonata Hybrid Sedan 2012   \n",
       "4     00005.jpg           106     Ford F-450 Super Duty Crew Cab 2012   \n",
       "...         ...           ...                                     ...   \n",
       "8139  08140.jpg            78  Chrysler Town and Country Minivan 2012   \n",
       "8140  08141.jpg           196           smart fortwo Convertible 2012   \n",
       "8141  08142.jpg           163       Mercedes-Benz SL-Class Coupe 2009   \n",
       "8142  08143.jpg           112                      Ford GT Coupe 2006   \n",
       "8143  08144.jpg            17                     Audi 100 Sedan 1994   \n",
       "\n",
       "        body type  \n",
       "0           Coupe  \n",
       "1           Sedan  \n",
       "2           Truck  \n",
       "3           Sedan  \n",
       "4           Truck  \n",
       "...           ...  \n",
       "8139          Van  \n",
       "8140  Convertible  \n",
       "8141        Coupe  \n",
       "8142        Coupe  \n",
       "8143        Sedan  \n",
       "\n",
       "[8144 rows x 4 columns]"
      ]
     },
"execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 8,
   "id": "43ed183a-e508-47db-9c74-9903e50354b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [filen, train_labels, class_name, body type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Show that all data is labeled\n",
    "unknowns = data[data[\"body type\"] == \"Unknown\"]\n",
    "print(unknowns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a383a9d-0459-402c-8bbb-f3b43eb2e5ee",
   "metadata": {},
   "source": [
    "Body types end"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 9,
   "id": "2ce39e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to construct custom Dataset Class to later use for DataLoader for models\n",
    "class CarsDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, transform=None, supervised=True, use_body_type=False, body_type_to_idx=None):\n",
    "        self.df = df\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.supervised = supervised\n",
    "        self.use_body_type = use_body_type\n",
    "        self.body_type_to_idx = body_type_to_idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        row = self.df.iloc[ind]\n",
    "        img_path = ''\n",
    "        if 'train' in self.images_dir:\n",
    "            img_path = os.path.join(self.images_dir, 'cars_train') # folder is nested /cars_train/cars_train\n",
    "        else:\n",
    "            img_path = os.path.join(self.images_dir, 'cars_test')\n",
    "\n",
    "        img_path = os.path.join(img_path, row[\"filen\"]) # path to specific image\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.supervised:\n",
    "            if self.use_body_type and self.body_type_to_idx is not None:\n",
    "                # Use body type label\n",
    "                body_type = row[\"body type\"]\n",
    "                label = self.body_type_to_idx[body_type]\n",
    "            else:\n",
    "                # Use original car model label\n",
    "                label = row[\"train_labels\"]\n",
    "            return img, label\n",
    "        else: # unsupervised; no image needed\n",
    "            return img "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d35866",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "### [ QUICK OVERVIEW OF SECTION ]"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 10,
   "id": "d68f8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations on images\n",
    "res_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224,224)), #resnets expect 224,224\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # ImageNet normalization\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
"execution_count": 11,
   "id": "030f9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/val/test (70/15/15)\n",
    "train_df, valtest_df = train_test_split(data, test_size=0.3, stratify=data[\"train_labels\"])\n",
    "val_df, test_df = train_test_split(valtest_df, test_size=0.5, stratify=valtest_df[\"train_labels\"])\n",
    "\n",
    "# construct CarsDatasets()\n",
    "train_data = CarsDataset(train_df, train_dir, transform=res_transforms, supervised=True)\n",
    "val_data = CarsDataset(val_df, train_dir, transform=res_transforms, supervised=True)\n",
    "test_data = CarsDataset(test_df, train_dir, transform=res_transforms, supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6117178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found nested directory! Using: /Users/bassamhajjawi/.cache/kagglehub/datasets/eduardo4jesus/stanford-cars-dataset/versions/1/cars_train/cars_train\n",
      "Found 8144 .jpg files in: /Users/bassamhajjawi/.cache/kagglehub/datasets/eduardo4jesus/stanford-cars-dataset/versions/1/cars_train/cars_train\n",
      "\n",
      "train_dir updated to: /Users/bassamhajjawi/.cache/kagglehub/datasets/eduardo4jesus/stanford-cars-dataset/versions/1/cars_train/cars_train\n",
      "Note: Datasets will be recreated in the Body Type Setup cell with the correct path\n"
     ]
    }
   ],
   "source": [
    "# Fix: Find the correct path where images actually are (handles nested directory structure)\n",
    "# This ensures train_dir points to the directory that actually contains the .jpg files\n",
    "actual_train_dir = train_dir\n",
    "if os.path.exists(train_dir):\n",
    "    contents = os.listdir(train_dir)\n",
    "    # Check if there's a nested cars_train directory\n",
    "    if 'cars_train' in contents and os.path.isdir(os.path.join(train_dir, 'cars_train')):\n",
    "        actual_train_dir = os.path.join(train_dir, 'cars_train')\n",
    "        print(f\"Found nested directory! Using: {actual_train_dir}\")\n",
    "    # Check if there are .jpg files directly\n",
    "    jpg_files = [f for f in contents if f.endswith('.jpg')]\n",
    "    if jpg_files:\n",
    "        print(f\"Found {len(jpg_files)} .jpg files directly in train_dir\")\n",
    "        actual_train_dir = train_dir\n",
    "    else:\n",
    "        # Search recursively for .jpg files\n",
    "        for root, dirs, files in os.walk(train_dir):\n",
    "            jpg_count = len([f for f in files if f.endswith('.jpg')])\n",
    "            if jpg_count > 0:\n",
    "                actual_train_dir = root\n",
    "                print(f\"Found {jpg_count} .jpg files in: {actual_train_dir}\")\n",
    "                break\n",
    "\n",
    "# Update train_dir to the correct path (Body Type Setup cell will use this)\n",
    "train_dir = actual_train_dir\n",
    "print(f\"\\ntrain_dir updated to: {train_dir}\")\n",
    "print(\"Note: Datasets will be recreated in the Body Type Setup cell with the correct path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e8590",
   "metadata": {},
   "source": [
    "#### [TODO]\n",
    "- construct DataLoaders with Datasets\n",
    "- import models: resnet18, resnet50, densenet 121, etc etc.\n",
    "- define model (layers, inputs, optimizer, loss)\n",
    "- train\n",
    "- evaluate\n",
    "- repeat?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4bb7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body types to predict: ['Convertible', 'Coupe', 'Hatchback', 'SUV', 'Sedan', 'Truck', 'Van', 'Wagon']\n",
      "Number of body type classes: 8\n",
      "Body type mapping: {'Convertible': 0, 'Coupe': 1, 'Hatchback': 2, 'SUV': 3, 'Sedan': 4, 'Truck': 5, 'Van': 6, 'Wagon': 7}\n",
      "\n",
      "Datasets recreated for body type prediction\n"
     ]
    }
   ],
   "source": [
    "# Setup for Body Type Prediction (instead of 196 car models)\n",
    "# Get unique body types and create mapping\n",
    "unique_body_types = sorted(data[\"body type\"].unique())\n",
    "body_type_to_idx = {body_type: idx for idx, body_type in enumerate(unique_body_types)}\n",
    "idx_to_body_type = {idx: body_type for body_type, idx in body_type_to_idx.items()}\n",
    "\n",
    "num_body_types = len(unique_body_types)\n",
    "print(f\"Body types to predict: {unique_body_types}\")\n",
    "print(f\"Number of body type classes: {num_body_types}\")\n",
    "print(f\"Body type mapping: {body_type_to_idx}\")\n",
    "\n",
    "# Recreate datasets with body type labels\n",
    "train_data = CarsDataset(train_df, train_dir, transform=res_transforms, supervised=True, \n",
    "                        use_body_type=True, body_type_to_idx=body_type_to_idx)\n",
    "val_data = CarsDataset(val_df, train_dir, transform=res_transforms, supervised=True,\n",
    "                      use_body_type=True, body_type_to_idx=body_type_to_idx)\n",
    "test_data = CarsDataset(test_df, train_dir, transform=res_transforms, supervised=True,\n",
    "                       use_body_type=True, body_type_to_idx=body_type_to_idx)\n",
    "\n",
    "print(f\"\\nDatasets recreated for body type prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8869718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6cb03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 179\n",
      "Val batches: 39\n",
      "Test batches: 39\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create DataLoaders for batching data\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a49d87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cpu\n",
      "Number of classes (body types): 8\n",
      "Predicting: ['Convertible', 'Coupe', 'Hatchback', 'SUV', 'Sedan', 'Truck', 'Van', 'Wagon']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set up ResNet50 model for BODY TYPE prediction\n",
    "# Using number of body type classes (not 196 car models)\n",
    "num_classes = num_body_types  # This was set in the body type setup cell\n",
    "\n",
    "# Load pretrained ResNet50 with ImageNet weights\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Replace the final fully connected layer for body type classes\n",
    "# ResNet50's fc layer expects 2048 input features (from avgpool)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded on: {device}\")\n",
    "print(f\"Number of classes (body types): {num_classes}\")\n",
    "print(f\"Predicting: {unique_body_types}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a1424c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: CrossEntropyLoss\n",
      "Optimizer: Adam (lr=0.001)\n",
      "Scheduler: StepLR (step_size=7, gamma=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()  # Standard classification loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "\n",
    "# Learning rate scheduler: reduces LR by factor of 0.1 every 7 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "print(\"Loss function: CrossEntropyLoss\")\n",
    "print(\"Optimizer: Adam (lr=0.001)\")\n",
    "print(\"Scheduler: StepLR (step_size=7, gamma=0.1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c773fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        epoch_loss: average loss for the epoch\n",
    "        epoch_acc: accuracy percentage for the epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move data to device (GPU or CPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)  # Body type labels are already 0-based (0 to num_body_types-1)\n",
    "        \n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: compute predictions\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9c1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model on validation set\n",
    "    \n",
    "    Returns:\n",
    "        epoch_loss: average loss for the epoch\n",
    "        epoch_acc: accuracy percentage for the epoch\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)  # Body type labels are already 0-based\n",
    "            \n",
    "            # Forward pass only (no backprop)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Track statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a607fe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_epoch(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m     17\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     18\u001b[0m train_accs\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Forward pass: compute predictions\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Backward pass: compute gradients\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    545\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 6: Training loop\n",
    "num_epochs = 10  # Number of complete passes through the training data\n",
    "best_val_acc = 0.0  # Track best validation accuracy\n",
    "\n",
    "# Lists to store training history\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "    print('-' * 20)\n",
    "    \n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    # Save best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_resnet50_model.pth')\n",
    "        print(f'✓ New best model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "\n",
    "print(f'\\nTraining complete! Best validation accuracy: {best_val_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a614c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set...\n",
      "Test Loss: 0.6363, Test Acc: 83.06%\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on test set...\")\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e9a73",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "### [QUICK OVERVIEW OF SECTION]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110e03c",
   "metadata": {},
   "source": [
    "Let's define some helper functions that we can use later on to help us with our data. These were used in HW4 from COGS 118B FA25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f9d14b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(mat):\n",
    "    return normalize(mat, norm='l2', axis=0) #normalize columns of matrix mat to unit length 1\n",
    "\n",
    "def viewimage(column):\n",
    "    normalized = (column - min(column)) / (max(column) - min(column))\n",
    "\n",
    "    return plt.imshow(normalized.reshape([60,60,3])) #reshape into RGB dimensions\n",
    "\n",
    "def eigsort(V, eigvals):\n",
    "    # [Vsort,Dsort] = eigsort(V, eigvals)\n",
    "    #\n",
    "    # Sorts a matrix eigenvectors and a array of eigenvalues in order \n",
    "    # of eigenvalue size, largest eigenvalue first and smallest eigenvalue\n",
    "    # last.\n",
    "    #\n",
    "    # Example usage:\n",
    "    # di, V = np.linarg.eig(L)\n",
    "    # Vnew, Dnew = eigsort(V, di)\n",
    "    #\n",
    "    # Tim Marks 2002\n",
    "    \n",
    "    # Sort the eigenvalues from largest to smallest. Store the sorted\n",
    "    # eigenvalues in the column vector lambd.\n",
    "    lohival = np.sort(eigvals)\n",
    "    lohiindex = np.argsort(eigvals)\n",
    "    lambd = np.flip(lohival)\n",
    "    index = np.flip(lohiindex)\n",
    "    Dsort = np.diag(lambd)\n",
    "    \n",
    "    # Sort eigenvectors to correspond to the ordered eigenvalues. Store sorted\n",
    "    # eigenvectors as columns of the matrix vsort.\n",
    "    M = np.size(lambd)\n",
    "    Vsort = np.zeros((M, M))\n",
    "    for i in range(M):\n",
    "        Vsort[:,i] = V[:,index[i]]\n",
    "    return Vsort, Dsort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83916f",
   "metadata": {},
   "source": [
    "First we want to initialize our CarsDataaset using our \"supervised\" parameter we defined in the Data section. This lets us ignore the labels of each image, since we don't need them right now. Let's look at the image size of the first few images to see whether they're all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddcb4a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffbe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb63a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
